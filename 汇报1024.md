for feature in features:

​	当前棋局状态$s$，合法动作集$a_1$，

​	删除掉特征feature，得到棋局状态$s'$，合法动作集$a_2$，

​	计算$Q(s,a) \forall a \in a_1 \cap a_2$	

​	计算$Q(s',a) \forall a \in a_1 \cap a2$

​	计算差值：$S[featuren] = Q(s,a) - Q(s',a)$

​	设定阈值$\delta$，若$S[feature] > \delta$，标注特征



对于特征f：

​	当前棋局状态$s$，对应合法动作集$a_1$

​	移除特征f，棋局状态变为$s'$，对应合法动作集$a_2$

​	取动作集$a = a_1 \cap a_2$

​	计算$Q(s,a)、Q(s',a)$

​	使用softmax函数对Q值进行处理：

​	$p(s,a) = \frac{exp(Q(s,a))}{\sum_{a}exp(Q(s,a))}$

​	$p(s',a)=\frac{exp(Q(s',a))}{\sum_{a}exp(Q(s',a))}$

​	$\nabla p = p(s, a) - p(s', a)$

​	$\nabla p$的大小代表特征f对于智能体决策的影响程度



对于特征f：

​	当前棋局状态$s$，对应合法动作集$a_1$，智能体决策动作为$\hat{a}$

​	移除特征f，棋局状态变为$s'$，对应合法动作集$a_2$

​	取动作集$a = a_1 \cap a_2$

​	计算$Q(s,a)、Q(s',a)$

	$P_{rem}(s, a) = \frac{exp(Q(s,a))}{\sum_{a'\ne \hat{a}}exp(Q(s, a'))} \forall a\ne \hat{a}$

​	$P_{rem}(s', a) = \frac{exp(Q(s',a))}{\sum_{a'\ne \hat{a}}exp(Q(s', a'))} \forall a\ne \hat{a}$

​	使用KL-散度计算差值：

​	$D_{KL} = P_{rem}(s', a)||P_{rem}(s,a)$

​	若$D_{KL}$较大，则说明该特征的改动不仅会影响到要解释的动作的Q值，还会影响到其他动作的Q值，即说明该特征与当前要解释的动作相关性较小



综合$\nabla p 和 D_{KL}$来评估特征重要性$S[f]$：

​	若$D_{KL}$较大，即特征与要解释的动作相关性较小，则$S[f]$应该较小，无论$\nabla p$是大是小

​	若$D{KL}$较小，则$S[f]$的大小取决于$\nabla p$



对于位置p：

​	定位我方智能体为M	

​	当前状态$s$，合法动作集$a_{pre}$

​	取敌方所有合法切能将棋子移动到位置p的动作$a_e$

​	for a' in $a_{e}$:

​		假设执行a'，将对应棋子落入位置p，状态为s'

​		取当前状态下M的合法动作集$a_{curr}$

​		$a = a_{pre} \cap a_{curr}$

​		计算Q(s, a)、Q(s', a)

​		若Q值有明显差异，则进行标注

​	

